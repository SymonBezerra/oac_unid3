# Organização e Arquitetura de Computadores
## 20 nov. 2023

## Nível de Linguagem de Montagem (Assembly)

- *assemble*: montagem
	+ o Assembly é uma linguagem cujo nível está 
	imediatamente acima do nível de máquina

	+ "Uma linguagem de montagem pura é uma linguagem
	na qual cada declaração produz exatamente
	uma instrução de máquina"

	+ abstração do código de máquina

- o programador de linguagem de montagem tem acesso
a todos os recursos e instruções disponíveis na máquina alvo
	+ isto não acontece quando executamos um Assembly
	através do sistema operacional

- um programa em Assembly só pode ser executado
em uma família de máquinas
	+ isto é, apenas naquela arquitetura-alvo

- por que programar em Assembly? R.=> desempenho
	+ exemplo de aplicação feita em Assembly: compiladores

- *Macros*: um nome que rotula a um pedaço do texto
	+ (similar ao cabeçalho `#define` do C ou `inline function` no C++)

	+ quando um macro é chamado, o código correspondente
	ao macro será colocado no código
		- o que é diferente de uma chamada de procedimento:
		o macro é chamado na montagem, enquanto o procedimento
		é chamado durante a execução

- *Símbolo*: rótulo ou valor ao qual é atribuído
um nome simbólico por meio de uma pseudoinstrução
	+ como uma espécie de variável

- O Assembler (montador) usa três tabelas:
tabela de símbolos, de pseudoinstruções e de opcodes
	- o Assembler gera um arquivo .o

## Ligação e carregamento

- Ligação dinâmica: ligação de procedimentos compilados separadamente
fazendo a ligação no momento que ele é chamado pela primeira vez
	+ o código fica externo ao binário, porém o binário sabe
	onde o código está
	+ exemplo: extensões `.dll`

- pré-compilador (NASM): análise léxica do Assembly

## Arquitetura de Computadores Paralelos

- apesar de não ser possível construir uma máquina
com $\Delta{t}$ de 1ps, é possível construir
1000 CPUs com ciclo $\Delta{t}$ de 1ns cada

- para enfrentear problemas cada vez maiores,
os arquitetos de computadores estão recorrendo
cada vez mais a computadores paralelos

- Paralelismo no chip => coprocessador => Multiprocessador
=> Multicomputador => Grade

- um modo de conseguir paralelismo no nível mais baixo
é emitir múltiplas instruções por ciclo de clock

- processadores VLIW => transferir do tempo de execução
para o tempo de compilação o trabalho de determinar
quais instruções podem ser emitidas em conjunto

## Paralelismo

- Todas as CPUs modernas, com paralelismo (*pipeline*)
têm um problema inerente:
	+ quando uma referência à memória encontra
	uma ausência das caches de nível 1 e 2,
	há uma longa espera até que a palavra
	requerida seja carregada na cache,
	portanto, o pipeline para

- Uma abordagem para lidar com isso: *multithreading*
	+ gerenciar múltiplos threads de controle
	simultaneamente em uma tentativa de tentar
	mascarar essas protelações

- para algumas aplicações, o multithreading não oferece
um ganho suficiente em desempenho
	+ para isso, estão sendo desenvolvidos
	chips multiprocessadores

	+ chip com pipeline dual
	+ chip com dois núcleos

- Coprocessadores: podem variar de um gabinete separado
ou uma área no chip principal (ponto flutuante)
	+ exemplo de ganho: criptografia

	+ criptografia de chave simétrica e chave pública

- Multiprocessador vs. multicomputador
	+ multiprocessador é um computador paralelo no qual
	todas as CPUs compartilham uma única memória

	+ enquanto os multicomputadores têm uma memória privada
	para cada CPU

- Multiprocessadores com barramento:
	+ sem cache
	+ com cache
	+ com cache e memórias privadas
		- considerando que há uma memória compartilhada para todos

- tradicionalmente, o barramento dos multicomputadores é feito em fibra

### MPPs - Processadores Maciçamente Paralelos

- supercomputadores milionários

- Opções populares: Pentium, UltraSPARC, PowerPC

- BlueGene, RedStorm

- hardware dedicado

- Google: Cluster (computadores em stock)
